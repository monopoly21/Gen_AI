{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLi6sU-Ry0J8"
      },
      "source": [
        "\n",
        "**1. Complete all the exercises from previous labs before proceeding further.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KqHDVeRyEM1"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**2. Implement Decision Tree algorithm without using inbuilt function**. \n",
        "\n",
        "a. Display Entropy and Information gain at every step. \n",
        "\n",
        "b. Display the decision tree.\n",
        "\n",
        "c. Give a sample input to the decision tree and display the output \n",
        "\n",
        "dataset = {\n",
        "\n",
        "  'Taste':['Salty',  'Spicy',  'Spicy',  'Spicy',  'Spicy',  'Sweet', 'Salty',  'Sweet',  Spicy',  'Salty'],\n",
        "\n",
        "'Temperature':['Hot',  'Hot',  'Hot',  'Cold',  'Hot',  'Cold','  Cold',  'Hot',  'Cold',  'Hot'],\n",
        "\n",
        "'Texture':['Soft',  'Soft',  'Hard',  'Hard',  'Hard',  'Soft',  'Soft',  'Soft',  'Soft',  'Hard'],\n",
        "\n",
        "'Eat':['No',  'No',  'Yes',  'No',  'Yes',  'Yes',  'No',  'Yes',  'Yes',  'Yes']\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Decision Tree:\n",
            "\n",
            "------------------------------\n",
            " Step :1\n",
            "Info Gain for Taste:1.7319146418983498\n",
            "Info Gain for Temperature:1.9219280948873623\n",
            "Info Gain for Texture:1.8954618442383215\n",
            "\n",
            "------------------------------\n",
            " Step :2\n",
            "Info Gain for Taste:2.873360713063872\n",
            "Info Gain for Texture:3.2822287189138013\n",
            "\n",
            "------------------------------\n",
            " Step :3\n",
            "Info Gain for Taste:2.873360713063872\n",
            "\n",
            "------------------------------\n",
            " Step :3\n",
            "Info Gain for Taste:2.239224006860804\n",
            "\n",
            "------------------------------\n",
            " Step :2\n",
            "Info Gain for Taste:2.239224006860804\n",
            "Info Gain for Texture:2.511802677427424\n",
            "\n",
            "------------------------------\n",
            " Step :3\n",
            "Info Gain for Taste:2.873360713063872\n",
            "\n",
            "------------------------------\n",
            " Step :3\n",
            "Info Gain for Taste:2.239224006860804\n",
            "\n",
            "üîç Prediction for sample input: {'Taste': 'Spicy', 'Temperature': 'Cold', 'Texture': 'Soft'}\n",
            "‚úÖ Predicted: Yes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_102082/1189025264.py:112: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  ent=-np.sum((counts[i]/total)*math.log2(counts[i]/total) for i in range(len(values)))\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import math\n",
        "\n",
        "# dataset = {\n",
        "#     'Taste': ['Salty', 'Spicy', 'Spicy', 'Spicy', 'Spicy', 'Sweet', 'Salty', 'Sweet', 'Spicy', 'Salty'],\n",
        "#     'Temperature': ['Hot', 'Hot', 'Hot', 'Cold', 'Hot', 'Cold', 'Cold', 'Hot', 'Cold', 'Hot'],\n",
        "#     'Texture': ['Soft', 'Soft', 'Hard', 'Hard', 'Hard', 'Soft', 'Soft', 'Soft', 'Soft', 'Hard'],\n",
        "#     'Eat': ['No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes']\n",
        "# }\n",
        "# df = pd.DataFrame(dataset)\n",
        "\n",
        "# def entropy(target_col):\n",
        "#     values, counts = np.unique(target_col, return_counts=True)\n",
        "#     entropy_val = -np.sum([\n",
        "#         (counts[i] / np.sum(counts)) * math.log2(counts[i] / np.sum(counts))\n",
        "#         for i in range(len(values))\n",
        "#     ])\n",
        "#     return entropy_val\n",
        "\n",
        "# def info_gain(data, split_attr, target_name=\"Eat\"):\n",
        "#     total_entropy = entropy(data[target_name])\n",
        "#     vals, counts = np.unique(data[split_attr], return_counts=True)\n",
        "\n",
        "#     weighted_entropy = np.sum([\n",
        "#         (counts[i] / np.sum(counts)) * entropy(data[data[split_attr] == vals[i]][target_name])\n",
        "#         for i in range(len(vals))\n",
        "#     ])\n",
        "\n",
        "#     gain = total_entropy - weighted_entropy\n",
        "#     print(f\"Info Gain on splitting on {split_attr}: {gain:.4f}\")\n",
        "#     return gain\n",
        "\n",
        "# def build_tree(data, original_data, features, target_attr=\"Eat\", parent_node_class=None, depth=0):\n",
        "#     indent = \"  \" * depth\n",
        "#     target_vals = data[target_attr]\n",
        "\n",
        "#     if len(np.unique(target_vals)) <= 1:\n",
        "#         print(f\"{indent}Leaf -> {np.unique(target_vals)[0]}\")\n",
        "#         return np.unique(target_vals)[0]\n",
        "\n",
        "#     elif len(data) == 0:\n",
        "#         unique_class, class_counts = np.unique(original_data[target_attr], return_counts=True)\n",
        "#         majority_index = np.argmax(class_counts)\n",
        "#         majority = unique_class[majority_index]\n",
        "#         print(f\"{indent}Leaf (empty) -> {majority}\")\n",
        "#         return majority\n",
        "\n",
        "#     elif len(features) == 0:\n",
        "#         print(f\"{indent}Leaf (no features) -> {parent_node_class}\")\n",
        "#         return parent_node_class\n",
        "\n",
        "#     else:\n",
        "#         unique_class, class_counts = np.unique(target_vals, return_counts=True)\n",
        "#         majority_index = np.argmax(class_counts)\n",
        "#         parent_node_class = unique_class[majority_index]\n",
        "\n",
        "#         gains = [info_gain(data, feature, target_attr) for feature in features]\n",
        "#         best_feature = features[np.argmax(gains)]\n",
        "#         print(f\"{indent}Node: {best_feature}\")\n",
        "#         tree = {best_feature: {}}\n",
        "#         features = [f for f in features if f != best_feature]\n",
        "\n",
        "#         for val in np.unique(data[best_feature]):\n",
        "#             print(f\"{indent}Branch {best_feature} == {val}\")\n",
        "#             sub_data = data[data[best_feature] == val]\n",
        "#             subtree = build_tree(sub_data, data, features, target_attr, parent_node_class, depth + 1)\n",
        "#             tree[best_feature][val] = subtree\n",
        "\n",
        "#         return tree\n",
        "\n",
        "# def predict(query, tree):\n",
        "#     for key in tree.keys():\n",
        "#         value = query.get(key)\n",
        "#         if value not in tree[key]:\n",
        "#             return \"Unknown\"\n",
        "#         result = tree[key][value]\n",
        "#         if isinstance(result, dict):\n",
        "#             return predict(query, result)\n",
        "#         else:\n",
        "#             return result\n",
        "\n",
        "# Build and test\n",
        "# features = list(df.columns)\n",
        "# features.remove(\"Eat\")\n",
        "\n",
        "# print(\"\\nüìä Decision Tree:\")\n",
        "# decision_tree = build_tree(df, df, features)\n",
        "\n",
        "# # Prediction test\n",
        "# sample_input = {'Taste': 'Spicy', 'Temperature': 'Cold', 'Texture': 'Soft'}\n",
        "# print(\"\\nüîç Prediction for sample input:\", sample_input)\n",
        "# print(\"‚úÖ Predicted:\", predict(sample_input, decision_tree))\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "dataset = {\n",
        "    'Taste': ['Salty', 'Spicy', 'Spicy', 'Spicy', 'Spicy', 'Sweet', 'Salty', 'Sweet', 'Spicy', 'Salty'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Hot', 'Cold', 'Hot', 'Cold', 'Cold', 'Hot', 'Cold', 'Hot'],\n",
        "    'Texture': ['Soft', 'Soft', 'Hard', 'Hard', 'Hard', 'Soft', 'Soft', 'Soft', 'Soft', 'Hard'],\n",
        "    'Eat': ['No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes']\n",
        "}\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "def entropy(data):\n",
        "    values,counts=np.unique(data,return_counts=True)\n",
        "    total=np.sum(counts)\n",
        "    ent=-np.sum((counts[i]/total)*math.log2(counts[i]/total) for i in range(len(values)))\n",
        "    return ent\n",
        "\n",
        "def info_gain(data,feauture_col,target_col):\n",
        "    total_ent=entropy(df[target_col])\n",
        "    for val in np.unique(df[feauture_col]):\n",
        "        subset_data=df[df[feauture_col]==val]\n",
        "        total=len(data)\n",
        "        weighted_ent=0\n",
        "        weighted_ent-=(len(subset_data)/len(data))*entropy(subset_data[target_col])\n",
        "        total_ent-=weighted_ent\n",
        "    return total_ent\n",
        "\n",
        "def build_tree(data,target_col,features,depth=0):\n",
        "\n",
        "    labels=df[target_col]\n",
        "\n",
        "    if len(labels)<=1:\n",
        "        return labels.iloc[0]\n",
        "    \n",
        "    if not features:\n",
        "        return labels.mode()[0]\n",
        "\n",
        "    info_gains={}\n",
        "    for feature in features:\n",
        "        info_gains[feature]=info_gain(data,feature,target_col)\n",
        "    \n",
        "    print(f\"\\n{'-'*30}\\n Step :{depth+1}\")\n",
        "    for feat,gain in info_gains.items():\n",
        "        print(f\"Info Gain for {feat}:{gain}\")\n",
        "\n",
        "    best_feature=max(info_gains,key=info_gains.get)    \n",
        "\n",
        "    tree={}\n",
        "    tree[best_feature]={}\n",
        "    rest_feature=[f for f in features if f!=best_feature]\n",
        "    for val in np.unique(df[best_feature]):\n",
        "        subset_data=df[df[best_feature]==val]\n",
        "        subset_tree=build_tree(subset_data,target_col,rest_feature,depth+1)\n",
        "        tree[best_feature][val]=subset_tree\n",
        "    \n",
        "    return tree\n",
        "\n",
        "def predict(tree,sample):\n",
        "    if not isinstance(tree,dict):\n",
        "        return tree\n",
        "    feature=next(iter(tree))\n",
        "    val=sample.get(feature,{})\n",
        "    if val in tree[feature]:\n",
        "        return predict(tree[feature][val],sample)\n",
        "    else:\n",
        "        return \"Unknown\"\n",
        "\n",
        "features = list(df.columns)\n",
        "features.remove(\"Eat\")\n",
        "\n",
        "print(\"\\nüìä Decision Tree:\")\n",
        "decision_tree = build_tree(df, \"Eat\", features,0)\n",
        "\n",
        "# Prediction test\n",
        "sample_input = {'Taste': 'Spicy', 'Temperature': 'Cold', 'Texture': 'Soft'}\n",
        "print(\"\\nüîç Prediction for sample input:\", sample_input)\n",
        "print(\"‚úÖ Predicted:\", predict( decision_tree,sample_input,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLle2wOkYxKX"
      },
      "source": [
        "**3. Repeat question 2 for a dataset selected on your own through internet resources.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea1SNH91bqjC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
